{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4126a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 videos in ./data/videos/val\n",
      "\n",
      "========== Video 1: X38A.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 1)\n",
      "\n",
      "========== Video 2: Y35K.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 3: X63C.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 4: Z33H.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 1)\n",
      "\n",
      "========== Video 5: Z49G.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 6: Z49X.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 1 (GT: 1)\n",
      "\n",
      "========== Video 7: Z01O.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 8: Z49D.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 9: Z45Y.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 0\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 0)\n",
      "\n",
      "========== Video 10: Y54Z.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 1 (GT: 1)\n",
      "\n",
      "========== Video 11: Z30F.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 0\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 0)\n",
      "\n",
      "========== Video 12: Y65C.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 1 (GT: 1)\n",
      "\n",
      "========== Video 13: X57F.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 1)\n",
      "\n",
      "========== Video 14: Z13N.mp4 ==========\n",
      "[WARNING] No ground-truth found in Excel for VIDEO=Z13N. Skipping.\n",
      "\n",
      "========== Video 15: X49O.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 16: Z62S.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 0\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 0)\n",
      "\n",
      "========== Video 17: Z28E.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 1 (GT: 1)\n",
      "\n",
      "========== Video 18: X61S.mp4 ==========\n",
      "[WARNING] No ground-truth found in Excel for VIDEO=X61S. Skipping.\n",
      "\n",
      "========== Video 19: X36T.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 0\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 0)\n",
      "\n",
      "========== Video 20: X85I.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 0\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 1 (GT: 0)\n",
      "\n",
      "========== Video 21: X49P.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 22: X45T.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 1)\n",
      "\n",
      "========== Video 23: Y99A.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 2\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 2 (GT: 2)\n",
      "\n",
      "========== Video 24: Y78H.mp4 ==========\n",
      "Ground truth:\n",
      "  GRS: 1\n",
      "Aggregated prediction (majority vote):\n",
      "  GRS: 0 (GT: 1)\n",
      "\n",
      "=== Per-target accuracy across all videos ===\n",
      "  GRS: 0.73\n",
      "\n",
      "Overall video-level accuracy (all OSATS correct): 0.73\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import random\n",
    "from PIL import Image\n",
    "from torchvision import transforms as T\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "import torch.nn as nn\n",
    "import scipy.stats\n",
    "\n",
    "# CONFIGURATION\n",
    "VIDEO_DIR = \"./data/videos/test\"\n",
    "MODEL_PATH = \"best_model_task1_epoch5_val0.8305.pt\"\n",
    "FRAME_TMP_DIR = \"./inference_frames\"\n",
    "EXCEL_FP = \"./data/OSATS_task1.xlsx\"\n",
    "NUM_VIDEOS = 24\n",
    "\n",
    "NUM_BLOCKS = 12\n",
    "WINDOW_SEC = 5\n",
    "FPS = 1\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "TARGET_COLS = [\n",
    "    \"GRS\"\n",
    "]\n",
    "NUM_OUTPUTS = len(TARGET_COLS)\n",
    "NUM_CLASSES = 4\n",
    "\n",
    "# MODEL DEFINITION\n",
    "class OSATSVideoResNetModel(nn.Module):\n",
    "    def __init__(self, num_outputs=NUM_OUTPUTS, num_classes=NUM_CLASSES,\n",
    "                 hidden_dim=128, lstm_layers=1, dropout_rate=0.5, bidirectional=True):\n",
    "        super().__init__()\n",
    "        self.num_outputs = num_outputs\n",
    "        self.num_classes = num_classes\n",
    "        self.base = resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "        self.base.fc = nn.Identity()\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size=512, hidden_size=hidden_dim,\n",
    "            num_layers=lstm_layers, batch_first=True,\n",
    "            dropout=(dropout_rate if lstm_layers > 1 else 0),\n",
    "            bidirectional=bidirectional\n",
    "        )\n",
    "        lstm_out = hidden_dim * (2 if bidirectional else 1)\n",
    "        self.head = nn.Sequential(\n",
    "            nn.Linear(lstm_out, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.LayerNorm(128),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(128, num_outputs * num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, S, C, H, W = x.shape\n",
    "        x = x.view(B * S, C, H, W)\n",
    "        feats = self.base(x)            # [B*S, 512]\n",
    "        feats = feats.view(B, S, -1)    # [B, S, 512]\n",
    "        seq_out, _ = self.lstm(feats)\n",
    "        out = self.head(seq_out)\n",
    "        return out.view(B, S, self.num_outputs, self.num_classes)\n",
    "\n",
    "# TRANSFORM\n",
    "frame_transform = T.Compose([\n",
    "    T.Resize((256, 256)),\n",
    "    T.CenterCrop(224),\n",
    "    T.GaussianBlur(kernel_size=9, sigma=(0.5, 0.5)),\n",
    "    T.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "    T.ToTensor(),\n",
    "    T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "# FRAME EXTRACTION\n",
    "def extract_frames(video_path, out_dir, fps=1):\n",
    "    os.makedirs(out_dir, exist_ok=True)\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frame_count = 0\n",
    "    frame_idx = 0\n",
    "    vid_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    interval = int(vid_fps // fps) if fps > 0 and vid_fps > 0 else 1\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        if frame_count % interval == 0:\n",
    "            out_path = os.path.join(out_dir, f\"frame_{frame_idx:04d}.jpg\")\n",
    "            cv2.imwrite(out_path, frame)\n",
    "            frame_idx += 1\n",
    "        frame_count += 1\n",
    "    cap.release()\n",
    "\n",
    "# INFERENCE DATASET\n",
    "class InferenceVideoDataset(Dataset):\n",
    "    def __init__(self, frame_dir, transform, num_blocks=8, window_sec=5, fps=1):\n",
    "        files = sorted(os.listdir(frame_dir))\n",
    "        self.frame_paths = [os.path.join(frame_dir, f) for f in files if f.endswith('.jpg')]\n",
    "        self.transform = transform\n",
    "        self.num_blocks = num_blocks\n",
    "        self.window_sec = window_sec\n",
    "        self.fps = fps\n",
    "        self.num_frames_per_block = window_sec * fps\n",
    "\n",
    "        total = len(self.frame_paths)\n",
    "        block_size = total // num_blocks if num_blocks > 0 else total\n",
    "\n",
    "        self.samples = []\n",
    "        for b in range(num_blocks):\n",
    "            block_start = b * block_size\n",
    "            start = block_start\n",
    "            end = min(start + self.num_frames_per_block, (b+1)*block_size, total)\n",
    "            block_indices = list(range(start, end))\n",
    "            while len(block_indices) < self.num_frames_per_block:\n",
    "                block_indices.append(-1)\n",
    "            paths = [self.frame_paths[i] if i != -1 else None for i in block_indices]\n",
    "            self.samples.append(paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        paths = self.samples[idx]\n",
    "        clips = []\n",
    "        for p in paths:\n",
    "            if p is None:\n",
    "                img = np.zeros((256,256,3), np.uint8)\n",
    "            else:\n",
    "                img = cv2.imread(p)\n",
    "                img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            img = Image.fromarray(img)\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            clips.append(img)\n",
    "        clip_tensor = torch.stack(clips, dim=0)\n",
    "        return clip_tensor\n",
    "\n",
    "def run_inference_on_video(video_path, model, device, tmp_dir, num_blocks, window_sec, fps):\n",
    "    # Clean up and create tmp frame directory\n",
    "    if os.path.exists(tmp_dir):\n",
    "        for f in os.listdir(tmp_dir):\n",
    "            os.remove(os.path.join(tmp_dir, f))\n",
    "    else:\n",
    "        os.makedirs(tmp_dir)\n",
    "    extract_frames(video_path, tmp_dir, fps=fps)\n",
    "    ds = InferenceVideoDataset(tmp_dir, frame_transform, num_blocks=num_blocks, window_sec=window_sec, fps=fps)\n",
    "    loader = DataLoader(ds, batch_size=1, shuffle=False)\n",
    "\n",
    "    all_preds = []\n",
    "    with torch.no_grad():\n",
    "        for xb in loader:\n",
    "            xb = xb.to(device)\n",
    "            out = model(xb)\n",
    "            preds = out.argmax(-1).squeeze(0)\n",
    "            all_preds.append(preds.cpu().numpy())\n",
    "    all_preds = np.concatenate(all_preds, axis=0)\n",
    "    return all_preds  # [num_blocks, NUM_OUTPUTS]\n",
    "\n",
    "def aggregate_predictions(preds):\n",
    "    # Majority vote (mode) per OSATS metric\n",
    "    video_pred_mode, _ = scipy.stats.mode(preds, axis=0, keepdims=False)\n",
    "    video_pred_mode = video_pred_mode.astype(int).tolist()\n",
    "    return video_pred_mode\n",
    "\n",
    "def main():\n",
    "    # Get all video files\n",
    "    all_videos = [os.path.join(VIDEO_DIR, f) for f in os.listdir(VIDEO_DIR)\n",
    "                  if f.lower().endswith(('.mp4', '.avi', '.mov', '.mkv'))]\n",
    "    print(f\"Found {len(all_videos)} videos in {VIDEO_DIR}\")\n",
    "\n",
    "    # Randomly select N videos\n",
    "    selected_videos = random.sample(all_videos, min(NUM_VIDEOS, len(all_videos)))\n",
    "\n",
    "    # Load Excel and model\n",
    "    df = pd.read_excel(EXCEL_FP)\n",
    "    model = OSATSVideoResNetModel(num_outputs=NUM_OUTPUTS, num_classes=NUM_CLASSES)\n",
    "    model.load_state_dict(torch.load(MODEL_PATH, map_location=DEVICE))\n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "\n",
    "    # For metrics over all videos\n",
    "    all_video_preds = []\n",
    "    all_video_gts = []\n",
    "\n",
    "    for i, video_path in enumerate(selected_videos):\n",
    "        print(f\"\\n========== Video {i+1}: {os.path.basename(video_path)} ==========\")\n",
    "\n",
    "        # Try to find VIDEO_ID for this video (assumes filename or path contains video id)\n",
    "        base_video_id = os.path.splitext(os.path.basename(video_path))[0]\n",
    "        row = df[df['VIDEO'].astype(str) == str(base_video_id)]\n",
    "        if row.empty:\n",
    "            print(f\"[WARNING] No ground-truth found in Excel for VIDEO={base_video_id}. Skipping.\")\n",
    "            continue\n",
    "        gt_scores = row.iloc[0][TARGET_COLS].values.astype(int)\n",
    "\n",
    "        # Run inference\n",
    "        preds = run_inference_on_video(video_path, model, DEVICE, FRAME_TMP_DIR,\n",
    "                                       num_blocks=NUM_BLOCKS, window_sec=WINDOW_SEC, fps=FPS)\n",
    "\n",
    "        # Aggregate: single prediction per video\n",
    "        video_pred_mode = aggregate_predictions(preds)\n",
    "        all_video_preds.append(video_pred_mode)\n",
    "        all_video_gts.append(gt_scores)\n",
    "\n",
    "        print(\"Ground truth:\")\n",
    "        for j, col in enumerate(TARGET_COLS):\n",
    "            print(f\"  {col}: {int(gt_scores[j])}\")\n",
    "        print(\"Aggregated prediction (majority vote):\")\n",
    "        for j, col in enumerate(TARGET_COLS):\n",
    "            print(f\"  {col}: {video_pred_mode[j]} (GT: {int(gt_scores[j])})\")\n",
    "\n",
    "    if len(all_video_preds) == 0:\n",
    "        print(\"No videos processed!\")\n",
    "        return\n",
    "\n",
    "    # Convert to numpy arrays for metrics\n",
    "    all_video_preds = np.stack(all_video_preds, axis=0)\n",
    "    all_video_gts = np.stack(all_video_gts, axis=0)\n",
    "\n",
    "    # Calculate and print per-target accuracy\n",
    "    print(\"\\n=== Per-target accuracy across all videos ===\")\n",
    "    for j, col in enumerate(TARGET_COLS):\n",
    "        acc = np.mean(all_video_preds[:, j] == all_video_gts[:, j])\n",
    "        print(f\"  {col}: {acc:.2f}\")\n",
    "\n",
    "    # Optionally, print overall accuracy (all metrics correct at once)\n",
    "    all_correct = np.all(all_video_preds == all_video_gts, axis=1)\n",
    "    overall_acc = np.mean(all_correct)\n",
    "    print(f\"\\nOverall video-level accuracy (all OSATS correct): {overall_acc:.2f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "daa",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
